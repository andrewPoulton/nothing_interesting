{
    "attention_probs_dropout_prob": 0.1,
    "gradient_checkpointing": false,
    "hidden_act": "gelu",
    "hidden_dropout_prob": 0.1,
    "hidden_size": 96,
    "initializer_range": 0.02,
    "intermediate_size": 384,
    "layer_norm_eps": 1e-12,
    "max_position_embeddings": 512,
    "model_type": "bert",
    "num_attention_heads": 3,
    "num_hidden_layers": 2,
    "pad_token_id": 0,
    "type_vocab_size": 4,
    "vocab_size": 30522,

    "output_attentions": true,

    "prenorm": false,
    "norm_type": "layer",

    "num_labels": 2,
    "batch_size": 32,
    "log_interval": 1,

    "warmup_steps": 100,
    "total_steps": 10000,
    "max_lr": 1e-4,

    "train_data_percent": 100,
    "data_source": "scientsbank",
    "val_data_percent": 100
}